{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidroy/anaconda3/envs/3d_vision/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sidroy/anaconda3/envs/3d_vision/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sidroy/anaconda3/envs/3d_vision/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sidroy/anaconda3/envs/3d_vision/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sidroy/anaconda3/envs/3d_vision/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sidroy/anaconda3/envs/3d_vision/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import matplotlib\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "\n",
    "import utils.binvox_visualization\n",
    "import utils.data_loaders\n",
    "import utils.data_transforms\n",
    "import utils.network_utils\n",
    "\n",
    "# Fix problem: no $DISPLAY environment variable\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime as dt\n",
    "from pprint import pprint\n",
    "\n",
    "from config import cfg\n",
    "from core.train import train_net\n",
    "#from core.test import test_net\n",
    "#from core.inference import inference_net\n",
    "from core.demo import test_net\n",
    "#from core.demo_trial import test_net\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import skimage.measure as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use config:\n",
      "{'CONST': {'BATCH_SIZE': 64,\n",
      "           'CROP_IMG_H': 128,\n",
      "           'CROP_IMG_W': 128,\n",
      "           'DEVICE': '0',\n",
      "           'IMG_H': 224,\n",
      "           'IMG_W': 224,\n",
      "           'N_VIEWS_RENDERING': 2,\n",
      "           'N_VOX': 32,\n",
      "           'RNG_SEED': 0},\n",
      " 'DATASET': {'MEAN': [0.5, 0.5, 0.5],\n",
      "             'STD': [0.5, 0.5, 0.5],\n",
      "             'TEST_DATASET': 'ShapeNet'},\n",
      " 'DATASETS': {'INFERENCE': {'RENDERING_PATH': './datasets/DemoImage/%s/%s/rendering/%02d.png',\n",
      "                            'TAXONOMY_FILE_PATH': './datasets/DemoData.json'},\n",
      "              'PASCAL3D': {'ANNOTATION_PATH': '/home/sidroy/software/Pix2Vox/datasets/PASCAL3D/Annotations/%s_imagenet/%s.mat',\n",
      "                           'RENDERING_PATH': '/home/sidroy/software/Pix2Vox/datasets/PASCAL3D/Images/%s_imagenet/%s.JPEG',\n",
      "                           'TAXONOMY_FILE_PATH': './datasets/Pascal3D.json',\n",
      "                           'VOXEL_PATH': '/home/sidroy/software/Pix2Vox/datasets/PASCAL3D/CAD/%s/%02d.binvox'},\n",
      "              'PIX3D': {'ANNOTATION_PATH': './LargeDatasets/Pix3D/pix3d.json',\n",
      "                        'RENDERING_PATH': './LargeDatasets/Pix3D/img/%s/%s.%s',\n",
      "                        'TAXONOMY_FILE_PATH': './datasets/Pix3D.json',\n",
      "                        'VOXEL_PATH': './LargeDatasets/Pix3D/model/%s/%s/%s.mat'},\n",
      "              'SHAPENET': {'RENDERING_PATH': './LargeDatasets/ShapeNetRendering/%s/%s/rendering/%02d.png',\n",
      "                           'TAXONOMY_FILE_PATH': './datasets/ShapeNet.json',\n",
      "                           'VOXEL_PATH': './LargeDatasets/ShapeNetVox32/%s/%s/model.binvox'}},\n",
      " 'DIR': {'OUT_PATH': './output',\n",
      "         'RANDOM_BG_PATH': '/home/hzxie/Datasets/SUN2012/JPEGImages'},\n",
      " 'NETWORK': {'LEAKY_VALUE': 0.2,\n",
      "             'TCONV_USE_BIAS': False,\n",
      "             'USE_MERGER': True,\n",
      "             'USE_REFINER': True},\n",
      " 'TEST': {'RANDOM_BG_COLOR_RANGE': [[240, 240], [240, 240], [240, 240]],\n",
      "          'VOXEL_THRESH': [0.2, 0.3, 0.4, 0.5]},\n",
      " 'TRAIN': {'BETAS': [0.9, 0.999],\n",
      "           'BRIGHTNESS': 0.4,\n",
      "           'CONTRAST': 0.4,\n",
      "           'DECODER_LEARNING_RATE': 0.001,\n",
      "           'DECODER_LR_MILESTONES': [150],\n",
      "           'ENCODER_LEARNING_RATE': 0.001,\n",
      "           'ENCODER_LR_MILESTONES': [150],\n",
      "           'EPOCH_START_USE_MERGER': 0,\n",
      "           'EPOCH_START_USE_REFINER': 0,\n",
      "           'GAMMA': 0.5,\n",
      "           'MERGER_LEARNING_RATE': 0.0001,\n",
      "           'MERGER_LR_MILESTONES': [150],\n",
      "           'MOMENTUM': 0.9,\n",
      "           'NOISE_STD': 0.1,\n",
      "           'NUM_EPOCHES': 250,\n",
      "           'NUM_WORKER': 4,\n",
      "           'POLICY': 'adam',\n",
      "           'RANDOM_BG_COLOR_RANGE': [[225, 255], [225, 255], [225, 255]],\n",
      "           'REFINER_LEARNING_RATE': 0.001,\n",
      "           'REFINER_LR_MILESTONES': [150],\n",
      "           'RESUME_TRAIN': False,\n",
      "           'SATURATION': 0.4,\n",
      "           'SAVE_FREQ': 10,\n",
      "           'UPDATE_N_VIEWS_RENDERING': False}}\n",
      "[INFO] 2020-02-18 00:13:23.461304 Collecting files of Taxonomy[ID=02691156, Name=aeroplane]\n",
      "[INFO] 2020-02-18 00:13:23.532254 Collecting files of Taxonomy[ID=02828884, Name=bench]\n",
      "[INFO] 2020-02-18 00:13:23.560726 Collecting files of Taxonomy[ID=02933112, Name=cabinet]\n",
      "[INFO] 2020-02-18 00:13:23.585460 Collecting files of Taxonomy[ID=02958343, Name=car]\n",
      "[INFO] 2020-02-18 00:13:23.703659 Collecting files of Taxonomy[ID=03001627, Name=chair]\n",
      "[INFO] 2020-02-18 00:13:23.841642 Collecting files of Taxonomy[ID=03211117, Name=display]\n",
      "[INFO] 2020-02-18 00:13:23.858475 Collecting files of Taxonomy[ID=03636649, Name=lamp]\n",
      "[INFO] 2020-02-18 00:13:23.893719 Collecting files of Taxonomy[ID=03691459, Name=speaker]\n",
      "[INFO] 2020-02-18 00:13:23.922452 Collecting files of Taxonomy[ID=04090263, Name=rifle]\n",
      "[INFO] 2020-02-18 00:13:23.960444 Collecting files of Taxonomy[ID=04256520, Name=sofa]\n",
      "[INFO] 2020-02-18 00:13:24.009124 Collecting files of Taxonomy[ID=04379243, Name=table]\n",
      "[INFO] 2020-02-18 00:13:24.145262 Collecting files of Taxonomy[ID=04401088, Name=telephone]\n",
      "[INFO] 2020-02-18 00:13:24.164575 Collecting files of Taxonomy[ID=04530566, Name=watercraft]\n",
      "[INFO] 2020-02-18 00:13:24.195130 Complete collecting files of the dataset. Total files: 8770.\n",
      "[INFO] 2020-02-18 00:13:28.584327 Loading weights from ./pretrained_models/Pix2Vox-A-ShapeNet_old.pth ...\n",
      "Epoch ID of the current model is 153\n",
      "test data loader type is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e9306761d9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./output/tensorboard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgenerated_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendering_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_volume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insight/projects/Pix2Vox/core/demo.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(cfg, epoch_idx, output_dir, test_data_loader, test_writer, encoder, decoder, refiner, merger)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test data loader type is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msample_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtaxonomy_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendering_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mtaxonomy_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaxonomy_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaxonomy_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtaxonomy_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msample_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "PATH = 'pretrained_models/ckpt-epoch-0550.pth'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#checkpoint = (torch.load(PATH))\n",
    "\n",
    "print('Use config:')\n",
    "pprint(cfg)\n",
    "\n",
    "cfg.CONST.WEIGHTS = './pretrained_models/Pix2Vox-A-ShapeNet_old.pth'\n",
    "#cfg.CONST.WEIGHTS = './pretrained_models/ckpt-epoch-0550.pth'\n",
    "\n",
    "writer = SummaryWriter('./output/tensorboard')\n",
    "generated_volume, rendering_images = test_net(cfg,output_dir='./output')\n",
    "\n",
    "print(generated_volume.shape)\n",
    "volume = generated_volume.reshape(32,32,32)\n",
    "print(volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = rendering_images.cpu().numpy()\n",
    "print(img_array.shape)\n",
    "for i in range(4,5):\n",
    "    image_array = img_array[:,i,:,:,:]\n",
    "    print(image_array.shape)\n",
    "    image_array = image_array.reshape(image_array.shape[2],image_array.shape[3],3)\n",
    "    print(image_array.shape)\n",
    "    %matplotlib notebook\n",
    "    fig = plt.figure(i)\n",
    "    plt.imshow(image_array)\n",
    "    print(\"mean = {}\".format(np.mean(image_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.set_aspect('equal')\n",
    "volume_plot = volume.squeeze().__ge__(0.1)\n",
    "ax.voxels(volume_plot, facecolor='k', edgecolor=\"b\")\n",
    "ax.view_init(0,70)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig(\"3D_reco.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.set_aspect('equal')\n",
    "volume_plot = volume.squeeze().__ge__(0.3)\n",
    "ax.voxels(volume_plot, facecolor='k', edgecolor=\"b\")\n",
    "ax.view_init(0,70)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig(\"3D_reco.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.set_aspect('equal')\n",
    "volume_plot = volume.squeeze().__ge__(0.35)\n",
    "ax.voxels(volume_plot, facecolor='k', edgecolor=\"b\")\n",
    "ax.view_init(0,70)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig(\"3D_reco.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.set_aspect('equal')\n",
    "volume = volume.squeeze().__ge__(0.3)\n",
    "ax.voxels(volume, facecolor='r',edgecolor=\"k\")\n",
    "ax.view_init(30, 240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts, faces = createMesh(volume)\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_trisurf(verts[:, 0], verts[:,1], faces, verts[:, 2], linewidth=0.2, antialiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "#ax.set_aspect('equal')\n",
    "volume = volume.squeeze().__ge__(0.3)\n",
    "ax.voxels(volume, facecolor='r',edgecolor=\"k\")\n",
    "ax.view_init(30, 240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts, faces = createMesh(volume.squeeze().__ge__(0.2))\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_trisurf(verts[:, 0], verts[:,1], faces, verts[:, 2], linewidth=0.2, antialiased=True)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMesh(vox, step=1, threshold = 0.5) :   \n",
    "\n",
    "    vox = np.pad(vox, step)\n",
    "\n",
    "    verts, faces, normals, values = sm.marching_cubes_lewiner(vox, 0.5, step_size=step)\n",
    "\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts, faces = createMesh(volume)\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_trisurf(verts[:, 0], verts[:,1], faces, verts[:, 2], linewidth=0.2, antialiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rendering_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
